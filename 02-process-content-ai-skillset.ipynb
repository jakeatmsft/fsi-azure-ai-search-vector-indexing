{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70e179a3",
      "metadata": {},
      "source": [
        "# 02a â€” Preview layout + embedding skills (Document Intelligence + Azure OpenAI)\n",
        "\n",
        "This notebook uses preview skills in Azure AI Search (2024-11-01-preview) to:\n",
        "- Extract markdown structure using DocumentIntelligenceLayoutSkill\n",
        "- Split into overlapping chunks with SplitSkill\n",
        "- Generate embeddings with AzureOpenAIEmbeddingSkill\n",
        "- Map outputs to your existing index fields via indexer output mappings (no index projections)\n",
        "\n",
        "Prereqs:\n",
        "- Ensure your Search service/region supports API version 2024-11-01-preview\n",
        "- Run 01-create-index.ipynb first so the index exists and vectorizer is configured in schema.json\n",
        "- Ensure your .env has: SEARCH_*, OPENAI_*, BLOB_*, DOC_INTELLIGENCE_APIM_KEY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a85ab4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from dotenv import load_dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0b0ab3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration from .env\n",
        "load_dotenv()\n",
        "\n",
        "config = {\n",
        "    'search_service_name': os.getenv('SEARCH_SERVICE_NAME'),\n",
        "    'search_admin_key': os.getenv('SEARCH_ADMIN_KEY'),\n",
        "    'search_index_name': os.getenv('SEARCH_INDEX_NAME'),\n",
        "    'search_api_version': '2024-11-01-preview',  # forced preview for DI + Embedding skills,\n",
        "    'blob_service_name': os.getenv('BLOB_SERVICE_NAME'),\n",
        "    'blob_container': os.getenv('BLOB_CONTAINER'),\n",
        "    'blob_key': os.getenv('BLOB_KEY'),\n",
        "    'openai_api_base': os.getenv('OPENAI_API_BASE'),\n",
        "    'openai_api_key': os.getenv('OPENAI_API_KEY'),\n",
        "    'openai_api_version': os.getenv('OPENAI_API_VERSION', '2024-02-01'),\n",
        "    'openai_embedding_model': os.getenv('OPENAI_EMBEDDING_MODEL'),  # deployment name\n",
        "    'openai_embedding_model_name': os.getenv('OPENAI_EMBEDDING_MODEL_NAME'),  # optional model name\n",
        "    'doc_intelligence_apim_key': os.getenv('DOC_INTELLIGENCE_APIM_KEY'),\n",
        "    'cognitive_services_key': os.getenv('COGNITIVE_SERVICES_KEY'),\n",
        "    'doc_intelligence_endpoint': os.getenv('DOC_INTELLIGENCE_ENDPOINT'),\n",
        "}\n",
        "\n",
        "for k, v in config.items():\n",
        "    print(f'{k}: {v}')\n",
        "\n",
        "search_service_name = config['search_service_name']\n",
        "search_service_url = f'https://{search_service_name}.search.windows.net'\n",
        "search_admin_key = config['search_admin_key']\n",
        "index_name = config['search_index_name']\n",
        "# Force the preview API version regardless of env to avoid 400s\n",
        "api_version = '2024-11-01-preview'\n",
        "print('Using Search API version:', api_version)\n",
        "\n",
        "blob_service_name = config['blob_service_name']\n",
        "blob_container = config['blob_container']\n",
        "blob_key = config['blob_key']\n",
        "blob_connection_string = 'DefaultEndpointsProtocol=https;AccountName=' + blob_service_name + ';AccountKey=' + blob_key + ';EndpointSuffix=core.windows.net'\n",
        "\n",
        "azure_openai_base = config['openai_api_base']\n",
        "azure_openai_key = config['openai_api_key']\n",
        "azure_openai_api_version = config['openai_api_version']\n",
        "azure_openai_embeddings_deployment = config['openai_embedding_model']\n",
        "azure_openai_embeddings_model_name = config['openai_embedding_model_name'] or config['openai_embedding_model']\n",
        "\n",
        "cogsvc_key = config['cognitive_services_key']\n",
        "\n",
        "# Using Cognitive Services multi-service key for skillset\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'api-key': search_admin_key\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7d5e6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpers for Search REST calls\n",
        "def _url(path):\n",
        "    if '?' in path:\n",
        "        return f'{search_service_url}{path}&api-version={api_version}'\n",
        "    return f'{search_service_url}{path}?api-version={api_version}'\n",
        "\n",
        "def search_get(path):\n",
        "    return requests.get(_url(path), headers=headers)\n",
        "\n",
        "def search_put(path, payload):\n",
        "    return requests.put(_url(path), headers=headers, data=json.dumps(payload))\n",
        "\n",
        "def search_post(path, payload):\n",
        "    return requests.post(_url(path), headers=headers, data=json.dumps(payload))\n",
        "\n",
        "def search_delete(path):\n",
        "    return requests.delete(_url(path), headers=headers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b094c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create or update the Blob data source (raw documents)\n",
        "data_source_name = 'blob-raw-docs'\n",
        "data_source = {\n",
        "  'name': data_source_name,\n",
        "  'type': 'azureblob',\n",
        "  'credentials': { 'connectionString': blob_connection_string },\n",
        "  'container': { 'name': blob_container }\n",
        "}\n",
        "resp = search_put(f'/datasources/{data_source_name}', data_source)\n",
        "print('datasource:', resp.status_code, resp.text[:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bd9c6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create or update the preview skillset (DI Layout + Split + AOAI Embedding)\n",
        "skillset_name = 'content-processing-skillset-preview'\n",
        "skills = [\n",
        "  {\n",
        "    '@odata.type': '#Microsoft.Skills.Util.DocumentIntelligenceLayoutSkill',\n",
        "    'name': 'di-layout',\n",
        "    'context': '/document',\n",
        "    'outputMode': 'oneToMany',\n",
        "    'markdownHeaderDepth': 'h3',\n",
        "    'inputs': [ { 'name': 'file_data', 'source': '/document/file_data' } ],\n",
        "    'outputs': [ { 'name': 'markdown_document', 'targetName': 'markdownDocument' } ]\n",
        "  },\n",
        "  {\n",
        "    '@odata.type': '#Microsoft.Skills.Text.SplitSkill',\n",
        "    'name': 'markdown-split',\n",
        "    'description': 'Split markdown content into overlapping chunks',\n",
        "    'context': '/document/markdownDocument/*',\n",
        "    'defaultLanguageCode': 'en',\n",
        "    'textSplitMode': 'pages',\n",
        "    'maximumPageLength': 700,\n",
        "    'pageOverlapLength': 100,\n",
        "    'inputs': [ { 'name': 'text', 'source': '/document/markdownDocument/*/content' } ],\n",
        "    'outputs': [ { 'name': 'textItems', 'targetName': 'pages' } ]\n",
        "  },\n",
        "  {\n",
        "    '@odata.type': '#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill',\n",
        "    'name': 'embed-pages',\n",
        "    'context': '/document/markdownDocument/*/pages/*',\n",
        "    'inputs': [ { 'name': 'text', 'source': '/document/markdownDocument/*/pages/*' } ],\n",
        "    'outputs': [ { 'name': 'embedding', 'targetName': 'text_vector' } ],\n",
        "    'resourceUri': azure_openai_base,\n",
        "    'deploymentId': azure_openai_embeddings_deployment,\n",
        "    'apiKey': azure_openai_key,\n",
        "    'modelName': azure_openai_embeddings_model_name,\n",
        "  },\n",
        "  {\n",
        "    '@odata.type': '#Microsoft.Skills.Util.ShaperSkill',\n",
        "    'name': 'shape-title',\n",
        "    'context': '/document',\n",
        "    'inputs': [ { 'name': 'name', 'source': '/document/metadata_storage_name' } ],\n",
        "    'outputs': [ { 'name': 'output', 'targetName': 'title' } ]\n",
        "  }\n",
        "]\n",
        "\n",
        "skillset = {\n",
        "  'name': skillset_name,\n",
        "  'description': 'Preview skillset: DI Layout + Split + Azure OpenAI Embedding',\n",
        "  'skills': skills,\n",
        "  'cognitiveServices': { '@odata.type': '#Microsoft.Azure.Search.CognitiveServicesByKey', 'key': cogsvc_key }\n",
        "}\n",
        "\n",
        "resp = search_put(f'/skillsets/{skillset_name}', skillset)\n",
        "# print('skillset:', resp.status_code, resp.text[:30,\n",
        "#   {\n",
        "#     '@odata.type': '#Microsoft.Skills.Util.ShaperSkill',\n",
        "#     'name': 'shape-parent',\n",
        "#     'context': '/document',\n",
        "#     'inputs': [ { 'name': 'path', 'source': '/document/metadata_storage_path' } ],\n",
        "#     'outputs': [ { 'name': 'output', 'targetName': 'parent_id' } ]\n",
        "#   }\n",
        "# ]])\n",
        "# ,\n",
        "\n",
        "# Add index projections to write per-page results directly to the index\n",
        "skillset['indexProjections'] = {\n",
        "  'selectors': [\n",
        "    {\n",
        "      'targetIndexName': index_name,\n",
        "      'parentKeyFieldName': 'parent_id',\n",
        "      'sourceContext': '/document/markdownDocument/*/pages/*',\n",
        "      'generatedKeyName': 'chunk_id',\n",
        "      'mappings': [\n",
        "        { 'name': 'chunk', 'source': '/document/markdownDocument/*/pages/*' },\n",
        "        { 'name': 'vector', 'source': '/document/markdownDocument/*/pages/*/text_vector' },\n",
        "        { 'name': 'title', 'source': '/document/title' },\n",
        "        { 'name': 'url', 'source': '/document/metadata_storage_path' },\n",
        "        { 'name': 'file_name', 'source': '/document/metadata_storage_name' },\n",
        "        { 'name': 'last_updated', 'source': '/document/metadata_storage_last_modified' }\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  'parameters': { 'projectionMode': 'skipIndexingParentDocuments' }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da66e070",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create or update the indexer that applies the skillset and writes to the index\n",
        "indexer_name = 'blob-to-index-with-skillset-preview'\n",
        "indexer = {\n",
        "  'name': indexer_name,\n",
        "  'dataSourceName': data_source_name,\n",
        "  'targetIndexName': index_name,\n",
        "  'skillsetName': skillset_name,\n",
        "  'parameters': {\n",
        "    'configuration': {\n",
        "      'parsingMode': 'default',\n",
        "      'dataToExtract': 'contentAndMetadata',\n",
        "      'failOnUnsupportedContentType': False,\n",
        "      'failOnUnprocessableDocument': False\n",
        "    }\n",
        "  },\n",
        "}\n",
        "\n",
        "_ = search_delete(f'/indexers/{indexer_name}')\n",
        "resp = search_put(f'/indexers/{indexer_name}', indexer)\n",
        "print('indexer:', resp.status_code, resp.text[:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b09b9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the indexer once and poll for completion\n",
        "run_resp = search_post(f'/indexers/{indexer_name}/run', {})\n",
        "print('run:', run_resp.status_code)\n",
        "\n",
        "def get_indexer_status():\n",
        "    r = search_get(f'/indexers/{indexer_name}/status')\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "for i in range(60):\n",
        "    status = get_indexer_status()\n",
        "    if not status:\n",
        "        print('Unable to get status')\n",
        "        break\n",
        "    last_result = status.get('lastResult')\n",
        "    if last_result and last_result.get('status') in ('success', 'transientFailure', 'persistentFailure'):\n",
        "        print(json.dumps(last_result, indent=2)[:1000])\n",
        "        break\n",
        "    time.sleep(5)\n",
        "else:\n",
        "    print('Timed out waiting for indexer to complete')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ad039b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}